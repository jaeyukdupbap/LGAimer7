{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln-Q60A2R54i"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtZkUTUNR54i"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import glob\n",
        "import re\n",
        "import holidays\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvxUedUdR54j"
      },
      "source": [
        "# Fixed RandomSeed & Setting Hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzY6Gc1UR54j"
      },
      "outputs": [],
      "source": [
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bo5Y-iiJR54j"
      },
      "outputs": [],
      "source": [
        "LOOKBACK, PREDICT, BATCH_SIZE, EPOCHS = 28, 7, 16, 30\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Engineering"
      ],
      "metadata": {
        "id": "KZN0FS0EchAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_date_features(df):\n",
        "    df = df.copy()\n",
        "    df['영업일자'] = pd.to_datetime(df['영업일자'])\n",
        "\n",
        "    # =================================\n",
        "    # 1. 기본 날짜 Features\n",
        "    # =================================\n",
        "\n",
        "    # 공휴일 정보 생성\n",
        "    kr_holidays = holidays.KR()\n",
        "    df['is_holiday'] = df['영업일자'].apply(lambda x: 1 if x in kr_holidays else 0)\n",
        "\n",
        "    # 기본 날짜 정보\n",
        "    df['month'] = df['영업일자'].dt.month\n",
        "    df['weekday'] = df['영업일자'].dt.weekday\n",
        "    df['weekday_name'] = df['영업일자'].dt.day_name().map({\n",
        "        'Monday': '월', 'Tuesday': '화', 'Wednesday': '수',\n",
        "        'Thursday': '목', 'Friday': '금', 'Saturday': '토', 'Sunday': '일'\n",
        "    })\n",
        "    df['is_weekend'] = df['weekday'].apply(lambda x: 1 if x >= 5 else 0)\n",
        "    df['weekofyear'] = df['영업일자'].dt.isocalendar().week.astype(int)\n",
        "    df['dayofmonth'] = df['영업일자'].dt.day\n",
        "    df['quarter'] = df['영업일자'].dt.quarter\n",
        "\n",
        "    # =================================\n",
        "    # 2. 수정된 공휴일 클러스터 분석\n",
        "    # ================================='\n",
        "\n",
        "    # 공휴일 전날/다음날 계산\n",
        "    df = df.sort_values('영업일자').reset_index(drop=True)\n",
        "    df['holiday_prev'] = df['is_holiday'].shift(1).fillna(0).astype(int)  # 전날이 공휴일\n",
        "    df['holiday_next'] = df['is_holiday'].shift(-1).fillna(0).astype(int)  # 다음날이 공휴일\n",
        "\n",
        "    # 공휴일 전날 (내일이 공휴일)\n",
        "    df['is_holiday_eve'] = df['holiday_next']\n",
        "    # 공휴일 다음날 (어제가 공휴일)\n",
        "    df['is_holiday_after'] = df['holiday_prev']\n",
        "\n",
        "    # 연휴 길이 계산 (분석 결과 반영)\n",
        "    df['holiday_cluster_length'] = (\n",
        "        df['is_holiday_eve'] + df['is_holiday'] + df['is_holiday_after']\n",
        "    )\n",
        "\n",
        "    # 공휴일 클러스터 점수 (분석 결과: 28.12/10.25 = 2.74배)\n",
        "    def get_holiday_cluster_score(row):\n",
        "        if row['holiday_cluster_length'] == 3:  # 3연휴: 2.74배\n",
        "            return 2.74\n",
        "        elif row['is_holiday'] and row['is_holiday_after']:  # 공휴일+다음날: 1.43배\n",
        "            return 1.43\n",
        "        elif row['is_holiday_after'] and not row['is_holiday']:  # 다음날만: 1.72배\n",
        "            return 1.72\n",
        "        elif row['is_holiday_eve'] and not row['is_holiday']:  # 전날만: 1.32배\n",
        "            return 1.32\n",
        "        elif row['is_holiday'] and not row['is_holiday_eve'] and not row['is_holiday_after']:  # 공휴일만: 1.23배\n",
        "            return 1.23\n",
        "        else:\n",
        "            return 1.0  # 평상시\n",
        "\n",
        "    df['holiday_effect_score'] = df.apply(get_holiday_cluster_score, axis=1)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "IeucMX92QA9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYKEXTGxR54j"
      },
      "source": [
        "# Data Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wbf6RccaR54j"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train = pd.read_csv('/content/drive/MyDrive/open/train/train.csv')\n",
        "train['매출수량'] = train['매출수량'].clip(lower=0) # 음수 값 0으로...\n",
        "train = add_date_features(train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsyTO0dTR54j"
      },
      "source": [
        "# Define Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnsVKQ53R54j"
      },
      "outputs": [],
      "source": [
        "class MultiOutputLSTM(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim=96, num_layers=2, output_dim=7, dropout_rate=0.3):\n",
        "        super(MultiOutputLSTM, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout_rate if num_layers > 1 else 0)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        out = self.dropout(out[:, -1, :])\n",
        "        return self.fc(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6K44uPQR54j"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_lstm(train_df):\n",
        "    trained_models = {}\n",
        "\n",
        "    for store_menu, group in tqdm(train_df.groupby(['영업장명_메뉴명']), desc ='Training LSTM'):\n",
        "        store_train = group.sort_values('영업일자').copy()\n",
        "        if len(store_train) < LOOKBACK + PREDICT:\n",
        "            continue\n",
        "\n",
        "        features = ['매출수량', 'month', 'is_holiday', 'is_weekend', 'weekofyear', 'dayofmonth',\n",
        "                    'quarter', 'holiday_effect_score'] # 추가 features\n",
        "        scaler = MinMaxScaler()\n",
        "        store_train[features] = scaler.fit_transform(store_train[features])\n",
        "        train_vals = store_train[features].values  # shape: (N, 1)\n",
        "\n",
        "        # 시퀀스 구성\n",
        "        X_train, y_train = [], []\n",
        "        for i in range(len(train_vals) - LOOKBACK - PREDICT + 1):\n",
        "            X_train.append(train_vals[i:i+LOOKBACK])\n",
        "            y_train.append(train_vals[i+LOOKBACK:i+LOOKBACK+PREDICT, 0])\n",
        "\n",
        "        X_train = torch.tensor(X_train).float().to(DEVICE)\n",
        "        y_train = torch.tensor(y_train).float().to(DEVICE)\n",
        "\n",
        "        model = MultiOutputLSTM(input_dim=len(features), output_dim=PREDICT).to(DEVICE)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "        criterion = nn.MSELoss()\n",
        "\n",
        "        model.train()\n",
        "        for epoch in range(EPOCHS):\n",
        "            idx = torch.randperm(len(X_train))\n",
        "            for i in range(0, len(X_train), BATCH_SIZE):\n",
        "                batch_idx = idx[i:i+BATCH_SIZE]\n",
        "                X_batch, y_batch = X_train[batch_idx], y_train[batch_idx]\n",
        "                output = model(X_batch)\n",
        "                loss = criterion(output, y_batch)\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        trained_models[store_menu] = {\n",
        "            'model': model.eval(),\n",
        "            'scaler': scaler,\n",
        "            'last_sequence': train_vals[-LOOKBACK:], # (28, 1)\n",
        "            'last_date': store_train['영업일자'].iloc[-1] # 수정\n",
        "        }\n",
        "\n",
        "    return trained_models"
      ],
      "metadata": {
        "id": "XyN40J_E3nkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_8L9NTsR54k"
      },
      "outputs": [],
      "source": [
        "# 학습\n",
        "trained_models = train_lstm(train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y59EBAfzR54k"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_lstm(test_df, trained_models, test_prefix: str):\n",
        "    results = []\n",
        "    features = ['매출수량', 'month', 'is_holiday', 'is_weekend', 'weekofyear', 'dayofmonth',\n",
        "                'quarter', 'holiday_effect_score'] # 추가 features\n",
        "\n",
        "    for store_menu, store_test in test_df.groupby(['영업장명_메뉴명']):\n",
        "        key = store_menu\n",
        "        if key not in trained_models:\n",
        "            continue\n",
        "\n",
        "        model = trained_models[key]['model']\n",
        "        scaler = trained_models[key]['scaler']\n",
        "        last_sequence = trained_models[key]['last_sequence']  # (28, 6)\n",
        "        last_date = trained_models[key]['last_date']\n",
        "\n",
        "        # test_df에 날짜 특성 추가\n",
        "        store_test = add_date_features(store_test)\n",
        "        store_test_sorted = store_test.sort_values('영업일자')\n",
        "\n",
        "        # 28일 데이터 추출 및 스케일링\n",
        "        recent_data = store_test_sorted[features].values[-LOOKBACK:]  # (28, 6)\n",
        "        if len(recent_data) < LOOKBACK:\n",
        "            continue\n",
        "\n",
        "        # 스케일링\n",
        "        recent_data_scaled = scaler.transform(recent_data)\n",
        "        x_input = torch.tensor([recent_data_scaled]).float().to(DEVICE)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred_scaled = model(x_input).squeeze().cpu().numpy()\n",
        "\n",
        "        # 역변환 (매출수량만)\n",
        "        restored = []\n",
        "        for i in range(PREDICT):\n",
        "            dummy = np.zeros((1, len(features)))\n",
        "            dummy[0, 0] = pred_scaled[i]  # 첫 번째 feature가 매출수량\n",
        "            restored_val = scaler.inverse_transform(dummy)[0, 0]\n",
        "            restored.append(max(restored_val, 0))\n",
        "\n",
        "        # 예측일자: TEST_00+1일 ~ TEST_00+7일\n",
        "        pred_dates = [f\"{test_prefix}+{i+1}일\" for i in range(PREDICT)]\n",
        "\n",
        "        for d, val in zip(pred_dates, restored):\n",
        "            results.append({\n",
        "                '영업일자': d,\n",
        "                '영업장명_메뉴명': store_menu,\n",
        "                '매출수량': val\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "M47-jQAK6TEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJuP9WG7R54k",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "all_preds = []\n",
        "\n",
        "# 모든 test_*.csv 순회\n",
        "test_files = sorted(glob.glob('/content/drive/MyDrive/open/test/TEST_*.csv'))\n",
        "\n",
        "for path in test_files:\n",
        "    test_df = pd.read_csv(path)\n",
        "    test_df['매출수량'] = test_df['매출수량'].clip(lower=0) # 음수 값 0으로...\n",
        "    test_df = add_date_features(test_df) # 수정\n",
        "\n",
        "    # 파일명에서 접두어 추출 (예: TEST_00)\n",
        "    filename = os.path.basename(path)\n",
        "    test_prefix = re.search(r'(TEST_\\d+)', filename).group(1)\n",
        "\n",
        "    pred_df = predict_lstm(test_df, trained_models, test_prefix)\n",
        "    all_preds.append(pred_df)\n",
        "\n",
        "full_pred_df = pd.concat(all_preds, ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDQdeQDMR54k"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXOu9samR54k"
      },
      "outputs": [],
      "source": [
        "def convert_to_submission_format(pred_df: pd.DataFrame, sample_submission: pd.DataFrame):\n",
        "    # (영업일자, 메뉴) → 매출수량 딕셔너리로 변환\n",
        "    pred_dict = dict(zip(\n",
        "        zip(pred_df['영업일자'], pred_df['영업장명_메뉴명']),\n",
        "        pred_df['매출수량']\n",
        "    ))\n",
        "\n",
        "    final_df = sample_submission.copy()\n",
        "\n",
        "    for row_idx in final_df.index:\n",
        "        date = final_df.loc[row_idx, '영업일자']\n",
        "        for col in final_df.columns[1:]:  # 메뉴명들\n",
        "            final_df.loc[row_idx, col] = pred_dict.get((date, (col,)), 0) # get((date, col), 0) 수정\n",
        "\n",
        "    return final_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DBRPxTVR54k"
      },
      "outputs": [],
      "source": [
        "sample_submission = pd.read_csv('/content/drive/MyDrive/open/sample_submission.csv')\n",
        "submission = convert_to_submission_format(full_pred_df, sample_submission)\n",
        "submission.to_csv('L_baseline_submission.csv', index=False, encoding='utf-8-sig')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}